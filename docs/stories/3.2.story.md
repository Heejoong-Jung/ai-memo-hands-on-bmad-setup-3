# Story 3.2: 실시간 음성-텍스트 변환

## Status

Draft

---

## Story

**As a** 사용자,  
**I want** 음성을 실시간으로 텍스트로 변환하여 노트에 입력할 수 있어,  
**so that** 빠르고 편리하게 음성 기반 메모를 작성할 수 있다.

---

## Acceptance Criteria

1. 음성 인식 시작 시 실시간으로 인식된 텍스트를 표시해야 한다
2. 음성 인식 중간 결과(interim results)를 실시간으로 보여줘야 한다
3. 음성 인식이 완료되면 최종 텍스트를 노트 입력 필드에 자동으로 삽입해야 한다
4. 음성 인식 중에는 시각적 피드백을 제공해야 한다 (상태 표시)
5. 음성 인식 오류 시 사용자에게 적절한 메시지를 표시해야 한다
6. 음성 인식 결과의 정확도를 높이기 위한 후처리 기능이 있어야 한다
7. 음성 인식 중에 사용자가 중단할 수 있어야 한다
8. 음성 인식 결과를 편집할 수 있어야 한다
9. 모든 기능에 대한 단위 테스트 및 통합 테스트를 작성해야 한다

---

## Tasks / Subtasks

- [ ] Task 1: 실시간 음성 인식 엔진 구현 (AC: 1, 2, 6)
  - [ ] `lib/speech/voice-recognition.ts` 파일 생성
  - [ ] SpeechRecognition 이벤트 핸들러 구현
  - [ ] 실시간 텍스트 스트리밍 처리
  - [ ] 중간 결과와 최종 결과 구분 처리
  - [ ] 텍스트 후처리 및 정확도 개선
  - [ ] 단위 테스트 작성

- [ ] Task 2: 음성 인식 UI 컴포넌트 구현 (AC: 3, 4, 7)
  - [ ] `components/speech/voice-recognition.tsx` 컴포넌트 생성
  - [ ] 실시간 텍스트 표시 영역
  - [ ] 음성 인식 상태 시각적 피드백
  - [ ] 시작/중지/중단 컨트롤 버튼
  - [ ] 인식 결과 미리보기
  - [ ] 컴포넌트 테스트 작성

- [ ] Task 3: 음성 인식 결과 편집 기능 (AC: 8)
  - [ ] 음성 인식 결과 편집 모드 구현
  - [ ] 텍스트 수정 및 보완 기능
  - [ ] 편집 완료 후 노트에 삽입
  - [ ] 편집 취소 기능
  - [ ] 단위 테스트 작성

- [ ] Task 4: 에러 핸들링 및 사용자 피드백 (AC: 5)
  - [ ] 음성 인식 에러 상황 처리
  - [ ] 네트워크 연결 문제 처리
  - [ ] 마이크 접근 문제 처리
  - [ ] 사용자 친화적 에러 메시지
  - [ ] 에러 복구 가이드 제공
  - [ ] 단위 테스트 작성

- [ ] Task 5: 노트 작성 폼과 통합 (AC: 3, 8)
  - [ ] `app/notes/new/form.tsx` 수정
  - [ ] 음성 인식 결과를 노트 본문에 삽입
  - [ ] 기존 텍스트와 음성 텍스트 병합
  - [ ] 커서 위치 기반 텍스트 삽입
  - [ ] 통합 테스트 작성

- [ ] Task 6: 통합 테스트 및 사용성 검증 (AC: 9)
  - [ ] 전체 음성 인식 플로우 테스트
  - [ ] 다양한 음성 품질 시나리오 테스트
  - [ ] 에러 상황 시뮬레이션 테스트
  - [ ] 사용자 경험 플로우 테스트

---

## Dev Notes

### 기술 스택 및 아키텍처 컨텍스트

**Web Speech API**
- SpeechRecognition API 사용
- 실시간 음성-텍스트 변환
- interimResults: true로 중간 결과 표시
- continuous: true로 연속 인식
- 한국어(ko-KR) 언어 설정
[Source: docs/epics/epic-3-voice-memo.md]

**음성 인식 이벤트**
- onstart: 음성 인식 시작
- onresult: 인식 결과 수신
- onerror: 인식 에러 발생
- onend: 음성 인식 종료
- 실시간 텍스트 스트리밍 처리
[Source: Web Speech API 문서]

**React 상태 관리**
- useState로 음성 인식 상태 관리
- useEffect로 이벤트 리스너 관리
- 실시간 UI 업데이트
- 사용자 경험 최적화
[Source: React 공식 문서 패턴]

### Epic 컨텍스트

**Epic 3: 음성인식 메모 작성**
- 음성인식 정확도 95% 이상 목표
- 음성-텍스트 변환 지연시간 2초 이내
- 실시간 음성-텍스트 변환으로 즉시 확인 가능
- 빠르고 편리한 음성 기반 메모 작성 경험
[Source: docs/epics/epic-3-voice-memo.md]

### 이전 스토리에서의 주요 인사이트

**Story 3.1: 음성인식 시스템 초기 설정 완료**
- `lib/speech/speech-recognition.ts`: SpeechRecognition 초기화
- `lib/speech/permission-manager.ts`: 권한 상태 관리
- `lib/speech/speech-utils.ts`: 브라우저 호환성 검사
- 한국어 설정 및 에러 핸들링 패턴
[Source: docs/stories/3.1.story.md]

**Story 2.x: 노트 관리 패턴**
- `app/notes/new/form.tsx`: 노트 작성 폼 구조
- shadcn/ui 컴포넌트 활용
- Server Actions 패턴
- 사용자 경험 중심의 UI 설계
[Source: app/notes/actions.ts, lib/db/notes.ts]

### 파일 위치 및 구조

**새로 생성할 파일:**
- `lib/speech/voice-recognition.ts` - 실시간 음성 인식 엔진
- `components/speech/voice-recognition.tsx` - 음성 인식 UI 컴포넌트
- `lib/speech/voice-recognition.test.ts` - 음성 인식 엔진 테스트
- `components/speech/voice-recognition.test.tsx` - 음성 인식 UI 테스트

**수정할 파일:**
- `app/notes/new/form.tsx` - 음성 인식 기능 통합

### 구현 가이드라인

**실시간 음성 인식 엔진 예시:**

```typescript
// lib/speech/voice-recognition.ts
// 실시간 음성-텍스트 변환 엔진
// SpeechRecognition 이벤트 처리 및 텍스트 스트리밍
// 관련 파일: components/speech/voice-recognition.tsx, app/notes/new/form.tsx

import { SpeechRecognitionManager } from './speech-recognition';

export type RecognitionState = 'idle' | 'listening' | 'processing' | 'error';
export type RecognitionResult = {
  interim: string;
  final: string;
  confidence: number;
};

export interface VoiceRecognitionCallbacks {
  onStart?: () => void;
  onResult?: (result: RecognitionResult) => void;
  onError?: (error: string) => void;
  onEnd?: () => void;
  onStateChange?: (state: RecognitionState) => void;
}

export class VoiceRecognitionEngine {
  private speechManager: SpeechRecognitionManager;
  private recognition: SpeechRecognition | webkitSpeechRecognition | null = null;
  private state: RecognitionState = 'idle';
  private callbacks: VoiceRecognitionCallbacks = {};
  private interimTranscript = '';
  private finalTranscript = '';

  constructor() {
    this.speechManager = new SpeechRecognitionManager();
  }

  /**
   * 음성 인식 엔진 초기화
   */
  async initialize(): Promise<void> {
    await this.speechManager.initialize();
    this.recognition = this.speechManager.getRecognition();
    
    if (!this.recognition) {
      throw new Error('SpeechRecognition을 초기화할 수 없습니다.');
    }

    this.setupEventListeners();
  }

  /**
   * 이벤트 리스너 설정
   */
  private setupEventListeners(): void {
    if (!this.recognition) return;

    this.recognition.onstart = () => {
      this.setState('listening');
      this.callbacks.onStart?.();
    };

    this.recognition.onresult = (event) => {
      this.handleRecognitionResult(event);
    };

    this.recognition.onerror = (event) => {
      this.handleRecognitionError(event);
    };

    this.recognition.onend = () => {
      this.setState('idle');
      this.callbacks.onEnd?.();
    };
  }

  /**
   * 음성 인식 결과 처리
   */
  private handleRecognitionResult(event: SpeechRecognitionEvent): void {
    this.interimTranscript = '';
    this.finalTranscript = '';

    for (let i = event.resultIndex; i < event.results.length; i++) {
      const result = event.results[i];
      const transcript = result[0].transcript;
      const confidence = result[0].confidence;

      if (result.isFinal) {
        this.finalTranscript += transcript;
      } else {
        this.interimTranscript += transcript;
      }
    }

    // 후처리 적용
    const processedInterim = this.postProcessText(this.interimTranscript);
    const processedFinal = this.postProcessText(this.finalTranscript);

    this.callbacks.onResult?.({
      interim: processedInterim,
      final: processedFinal,
      confidence: event.results[event.results.length - 1]?.[0]?.confidence || 0,
    });
  }

  /**
   * 음성 인식 에러 처리
   */
  private handleRecognitionError(event: SpeechRecognitionErrorEvent): void {
    this.setState('error');
    
    let errorMessage = '음성 인식 중 오류가 발생했습니다.';
    
    switch (event.error) {
      case 'no-speech':
        errorMessage = '음성이 감지되지 않았습니다. 다시 시도해주세요.';
        break;
      case 'audio-capture':
        errorMessage = '마이크에 접근할 수 없습니다. 마이크 권한을 확인해주세요.';
        break;
      case 'not-allowed':
        errorMessage = '마이크 권한이 거부되었습니다. 브라우저 설정에서 권한을 허용해주세요.';
        break;
      case 'network':
        errorMessage = '네트워크 연결에 문제가 있습니다. 인터넷 연결을 확인해주세요.';
        break;
      case 'aborted':
        errorMessage = '음성 인식이 중단되었습니다.';
        break;
      case 'language-not-supported':
        errorMessage = '지원하지 않는 언어입니다.';
        break;
    }

    this.callbacks.onError?.(errorMessage);
  }

  /**
   * 텍스트 후처리 (정확도 개선)
   */
  private postProcessText(text: string): string {
    return text
      .trim()
      .replace(/\s+/g, ' ') // 연속 공백 제거
      .replace(/[^\w\s가-힣.,!?]/g, '') // 특수문자 정리
      .replace(/([.!?])\s*([a-zA-Z가-힣])/g, '$1 $2'); // 문장 부호 후 공백 정리
  }

  /**
   * 음성 인식 시작
   */
  start(): void {
    if (!this.recognition || this.state === 'listening') {
      return;
    }

    this.interimTranscript = '';
    this.finalTranscript = '';
    this.recognition.start();
  }

  /**
   * 음성 인식 중지
   */
  stop(): void {
    if (!this.recognition || this.state !== 'listening') {
      return;
    }

    this.recognition.stop();
  }

  /**
   * 음성 인식 중단
   */
  abort(): void {
    if (!this.recognition) {
      return;
    }

    this.recognition.abort();
    this.setState('idle');
  }

  /**
   * 상태 설정 및 콜백 호출
   */
  private setState(newState: RecognitionState): void {
    if (this.state !== newState) {
      this.state = newState;
      this.callbacks.onStateChange?.(newState);
    }
  }

  /**
   * 현재 상태 반환
   */
  getState(): RecognitionState {
    return this.state;
  }

  /**
   * 콜백 함수 설정
   */
  setCallbacks(callbacks: VoiceRecognitionCallbacks): void {
    this.callbacks = { ...this.callbacks, ...callbacks };
  }

  /**
   * 리소스 정리
   */
  destroy(): void {
    if (this.recognition) {
      this.recognition.abort();
    }
    this.callbacks = {};
  }
}
```

**음성 인식 UI 컴포넌트 예시:**

```typescript
// components/speech/voice-recognition.tsx
// 실시간 음성 인식 UI 컴포넌트
// 음성 인식 상태 표시 및 컨트롤
// 관련 파일: lib/speech/voice-recognition.ts, app/notes/new/form.tsx

'use client';

import { useEffect, useState, useRef } from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardHeader, CardTitle, CardContent } from '@/components/ui/card';
import { VoiceRecognitionEngine, type RecognitionState, type RecognitionResult } from '@/lib/speech/voice-recognition';

interface VoiceRecognitionProps {
  onTextRecognized: (text: string) => void;
  onError: (error: string) => void;
}

export function VoiceRecognition({ onTextRecognized, onError }: VoiceRecognitionProps) {
  const [state, setState] = useState<RecognitionState>('idle');
  const [interimText, setInterimText] = useState('');
  const [finalText, setFinalText] = useState('');
  const [confidence, setConfidence] = useState(0);
  const [isInitialized, setIsInitialized] = useState(false);
  const engineRef = useRef<VoiceRecognitionEngine | null>(null);

  useEffect(() => {
    const initializeEngine = async () => {
      try {
        const engine = new VoiceRecognitionEngine();
        await engine.initialize();
        
        engine.setCallbacks({
          onStart: () => {
            setInterimText('');
            setFinalText('');
            setConfidence(0);
          },
          onResult: (result: RecognitionResult) => {
            setInterimText(result.interim);
            setFinalText(result.final);
            setConfidence(result.confidence);
            
            // 최종 결과가 있으면 부모 컴포넌트에 전달
            if (result.final) {
              onTextRecognized(result.final);
            }
          },
          onError: (error: string) => {
            onError(error);
          },
          onStateChange: (newState: RecognitionState) => {
            setState(newState);
          },
        });

        engineRef.current = engine;
        setIsInitialized(true);
      } catch (error) {
        onError('음성 인식 엔진을 초기화할 수 없습니다.');
      }
    };

    initializeEngine();

    return () => {
      if (engineRef.current) {
        engineRef.current.destroy();
      }
    };
  }, [onTextRecognized, onError]);

  const handleStart = () => {
    if (engineRef.current && state === 'idle') {
      engineRef.current.start();
    }
  };

  const handleStop = () => {
    if (engineRef.current && state === 'listening') {
      engineRef.current.stop();
    }
  };

  const handleAbort = () => {
    if (engineRef.current) {
      engineRef.current.abort();
    }
  };

  const renderRecognitionStatus = () => {
    switch (state) {
      case 'idle':
        return (
          <div className="flex items-center space-x-2">
            <div className="w-3 h-3 bg-gray-400 rounded-full"></div>
            <span className="text-gray-600">음성 인식 대기 중</span>
          </div>
        );
      case 'listening':
        return (
          <div className="flex items-center space-x-2">
            <div className="w-3 h-3 bg-green-500 rounded-full animate-pulse"></div>
            <span className="text-green-600">음성 인식 중...</span>
          </div>
        );
      case 'processing':
        return (
          <div className="flex items-center space-x-2">
            <div className="w-3 h-3 bg-blue-500 rounded-full animate-spin"></div>
            <span className="text-blue-600">처리 중...</span>
          </div>
        );
      case 'error':
        return (
          <div className="flex items-center space-x-2">
            <div className="w-3 h-3 bg-red-500 rounded-full"></div>
            <span className="text-red-600">오류 발생</span>
          </div>
        );
    }
  };

  if (!isInitialized) {
    return (
      <Card>
        <CardContent className="p-4">
          <p className="text-gray-600">음성 인식 엔진을 초기화하는 중...</p>
        </CardContent>
      </Card>
    );
  }

  return (
    <Card>
      <CardHeader>
        <CardTitle className="flex items-center justify-between">
          <span>음성 인식</span>
          {renderRecognitionStatus()}
        </CardTitle>
      </CardHeader>
      <CardContent className="space-y-4">
        {/* 인식 결과 표시 */}
        <div className="space-y-2">
          {finalText && (
            <div className="p-3 bg-green-50 border border-green-200 rounded-md">
              <p className="text-green-800 text-sm font-medium">최종 결과:</p>
              <p className="text-green-700">{finalText}</p>
              {confidence > 0 && (
                <p className="text-green-600 text-xs mt-1">
                  신뢰도: {Math.round(confidence * 100)}%
                </p>
              )}
            </div>
          )}
          
          {interimText && (
            <div className="p-3 bg-blue-50 border border-blue-200 rounded-md">
              <p className="text-blue-800 text-sm font-medium">인식 중:</p>
              <p className="text-blue-700 italic">{interimText}</p>
            </div>
          )}
        </div>

        {/* 컨트롤 버튼 */}
        <div className="flex space-x-2">
          {state === 'idle' && (
            <Button onClick={handleStart} className="flex-1">
              🎤 음성 인식 시작
            </Button>
          )}
          
          {state === 'listening' && (
            <>
              <Button onClick={handleStop} variant="outline" className="flex-1">
                ⏹️ 중지
              </Button>
              <Button onClick={handleAbort} variant="destructive" className="flex-1">
                ❌ 중단
              </Button>
            </>
          )}
        </div>

        {/* 사용 안내 */}
        <div className="text-xs text-gray-500 space-y-1">
          <p>• 마이크에 가까이서 명확하게 말씀해주세요</p>
          <p>• 조용한 환경에서 사용하면 인식률이 높아집니다</p>
          <p>• 인식이 완료되면 자동으로 노트에 추가됩니다</p>
        </div>
      </CardContent>
    </Card>
  );
}
```

### 의존성

**선행 스토리:**
- Story 3.1: 음성인식 시스템 초기 설정 (완료)

**후속 스토리:**
- Story 3.3: 음성인식 고급 기능 및 최적화

**블로킹 없음:**
- 이 스토리는 독립적으로 구현 가능
- Web Speech API와 권한 관리가 완료됨

### Testing

**테스트 프레임워크:**
- Vitest + TypeScript
- jsdom 환경에서 브라우저 API 모킹

**단위 테스트:**
- `VoiceRecognitionEngine` 클래스 테스트
  - 초기화 성공/실패 확인
  - 음성 인식 시작/중지/중단 확인
  - 이벤트 핸들러 동작 확인
  - 텍스트 후처리 확인
- 음성 인식 결과 처리 테스트
  - 중간 결과와 최종 결과 구분
  - 신뢰도 계산 확인
  - 에러 상황 처리 확인

**통합 테스트:**
- 음성 인식 UI 플로우 테스트
- 실시간 텍스트 업데이트 테스트
- 에러 상황 UI 표시 테스트

**모킹 전략:**
- `SpeechRecognition` 이벤트 모킹
- `SpeechRecognitionEvent` 결과 모킹
- `SpeechRecognitionErrorEvent` 에러 모킹
- 마이크 권한 상태 모킹

**테스트 케이스:**
1. **음성 인식 엔진**
   - 정상 초기화
   - 음성 인식 시작/중지/중단
   - 인식 결과 처리
   - 에러 상황 처리

2. **실시간 텍스트 처리**
   - 중간 결과 표시
   - 최종 결과 표시
   - 텍스트 후처리
   - 신뢰도 계산

3. **UI 컴포넌트**
   - 상태별 UI 표시
   - 컨트롤 버튼 동작
   - 에러 메시지 표시

4. **통합 플로우**
   - 음성 인식 → 텍스트 변환 → 노트 삽입
   - 에러 발생 → 사용자 안내 → 복구
   - 권한 문제 → 대체 방안 제시

**테스트 실행:**
- `pnpm test` - 전체 테스트 suite 실행
- `pnpm test lib/speech/voice-recognition` - 음성 인식 엔진 테스트만 실행
- `pnpm test components/speech/voice-recognition` - 음성 인식 UI 테스트만 실행

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-27 | 1.0 | Story 3.2 통합 버전 생성 | Bob (Scrum Master) |

---

## Dev Agent Record

_[Dev Agent가 구현 시 작성]_

---

## QA Results

_[QA Agent가 작성]_
